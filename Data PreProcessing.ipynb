{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "executive-sodium",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-serbia",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in the .mat data files\n",
    "# Retrieved from https://archive.ics.uci.edu/ml/datasets/Cuff-Less+Blood+Pressure+Estimation\n",
    "\n",
    "sample_file1 = scipy.io.loadmat(f'data/part_{1}.mat')\n",
    "part_1 = sample_file1['p'][0]\n",
    "sample_file2 = scipy.io.loadmat(f'data/part_{2}.mat')\n",
    "part_2 = sample_file2['p'][0]\n",
    "sample_file3 = scipy.io.loadmat(f'data/part_{3}.mat')\n",
    "part_3 = sample_file3['p'][0]\n",
    "sample_file4 = scipy.io.loadmat(f'data/part_{4}.mat')\n",
    "part_4 = sample_file4['p'][0]\n",
    "sample_file5 = scipy.io.loadmat(f'data/part_{5}.mat')\n",
    "part_5 = sample_file5['p'][0]\n",
    "sample_file6 = scipy.io.loadmat(f'data/part_{6}.mat')\n",
    "part_6 = sample_file6['p'][0]\n",
    "sample_file7 = scipy.io.loadmat(f'data/part_{7}.mat')\n",
    "part_7 = sample_file7['p'][0]\n",
    "sample_file8 = scipy.io.loadmat(f'data/part_{8}.mat')\n",
    "part_8 = sample_file8['p'][0]\n",
    "sample_file9 = scipy.io.loadmat(f'data/part_{9}.mat')\n",
    "part_9 = sample_file9['p'][0]\n",
    "sample_file10 = scipy.io.loadmat(f'data/part_{10}.mat')\n",
    "part_10 = sample_file10['p'][0]\n",
    "sample_file11 = scipy.io.loadmat(f'data/part_{11}.mat')\n",
    "part_11 = sample_file11['p'][0]\n",
    "sample_file12 = scipy.io.loadmat(f'data/part_{12}.mat')\n",
    "part_12 = sample_file12['p'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "looking-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299,)\n"
     ]
    }
   ],
   "source": [
    "# Combine all the sequences being used\n",
    "# These have been selected based on the absence of artifacts and irregularities\n",
    "\n",
    "data = np.concatenate(\n",
    "    (part_1[200:500],\n",
    "     part_2[200:400],\n",
    "     part_3[200:400],\n",
    "     part_4[200:400],\n",
    "     part_5[:309], part_5[311:700],\n",
    "     part_6[100:300], part_6[800:1000],\n",
    "     part_8[0:800],\n",
    "     part_7[0:400],\n",
    "     part_9[200:800],\n",
    "     part_10[0:200],\n",
    "     part_11[400:900],\n",
    "     part_12[0:200]),\n",
    "     axis=0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exempt-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays for segments of each signal\n",
    "ECGs = []\n",
    "PPGs = []\n",
    "ABPs = []\n",
    "\n",
    "# Iterate through each group of signals in the data\n",
    "for j, segment in enumerate(data):\n",
    "    PPG_sec = []\n",
    "    ABP_sec = []\n",
    "    ECG_sec = []\n",
    "\n",
    "    # Split each group into PPG, ABP, and ECG signals\n",
    "    PPG = segment[0]\n",
    "    ABP = segment[1]\n",
    "    ECG = segment[2]\n",
    "\n",
    "    # Find peaks in the PPG signal to divide each sequence into 2 heartbeat intervals\n",
    "    peaks, _ = find_peaks(np.concatenate(([min(PPG)],PPG,[min(PPG)])), prominence=0.3, distance=50)\n",
    "    peaks = peaks-1\n",
    "    peaks2 = peaks[::2]\n",
    "\n",
    "    # Add each 2 hearbeat sequence to the list of signals from that recording\n",
    "    for i, el in enumerate(peaks2):\n",
    "        if i+1 < len(peaks2):\n",
    "            ECG_sec.append(ECG[peaks2[i]:peaks2[i+1]])\n",
    "            PPG_sec.append(PPG[peaks2[i]:peaks2[i+1]])\n",
    "            ABP_sec.append(ABP[peaks2[i]:peaks2[i+1]])\n",
    "\n",
    "    # Add each list of recordings to the signals\n",
    "    ECGs.append(ECG_sec)\n",
    "    PPGs.append(PPG_sec)\n",
    "    ABPs.append(ABP_sec)\n",
    "\n",
    "# Convert each signal to a numpy array\n",
    "ECGs = np.array(ECGs)\n",
    "PPGs = np.array(PPGs)\n",
    "ABPs = np.array(ABPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "located-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(signal, max_len=256):\n",
    "    del_inds = {}\n",
    "    for i, sec in enumerate(signal):\n",
    "        for j, seq in enumerate(sec):\n",
    "            # If sequence is longer than 256, cut it to a length of 256\n",
    "            if max_len - len(seq) < 0:\n",
    "                seq = np.resize(seq[0:max_len],(max_len,1))\n",
    "            # Zero-pad each sequence so that it is 256 samples long\n",
    "            else:\n",
    "                seq = np.resize(np.pad(seq, (0,max_len-len(seq))),(max_len,1))\n",
    "            # Replace old sequence with resized sequence\n",
    "            sec[j] = seq\n",
    "\n",
    "        # Compute the mean for each sample point in a segment \n",
    "        means = np.mean(sec,axis=0)\n",
    "        means = [item[0] for item in means]\n",
    "        \n",
    "        # Compute the error between each sequence and the segment mean\n",
    "        errs = []\n",
    "        for seq in sec:\n",
    "            err = np.mean((np.reshape(seq, (256,))-means)**2)\n",
    "            errs.append(err)\n",
    "        \n",
    "        # Note the index for each sequence that is one standard deviation away from the segment mean\n",
    "        # Many of these segments are anomalies and will be removed in the next step\n",
    "        temp_inds = []\n",
    "        for j, err in enumerate(errs):\n",
    "            if err > (np.mean(errs) + np.std(errs)):\n",
    "                temp_inds.append(j)\n",
    "\n",
    "        del_inds[i] = temp_inds\n",
    "        \n",
    "    return signal, del_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "julian-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each signal\n",
    "ECGs, ECG_inds = pre_process(ECGs)\n",
    "PPGs, PPG_inds = pre_process(PPGs)\n",
    "ABPs, ABP_inds = pre_process(ABPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "healthy-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape signals into #,256,1 matrix after removing anomalies\n",
    "PPG_seq = np.empty((0,256,1))\n",
    "ECG_seq = np.empty((0,256,1))\n",
    "ABP_seq = np.empty((0,256,1))\n",
    "\n",
    "for i in range(len(PPGs)):\n",
    "    # Get unique anomalies combined from each signal\n",
    "    rmv = list(set(PPG_inds[i] + ECG_inds[i] + ABP_inds[i]))\n",
    "    \n",
    "    # Remove anomalies\n",
    "    newPPG = np.delete(PPGs[i], rmv, axis=0)\n",
    "    newECG = np.delete(ECGs[i], rmv, axis=0)\n",
    "    newABP = np.delete(ABPs[i], rmv, axis=0)\n",
    "    \n",
    "    # Append to matrix\n",
    "    PPG_seq = np.concatenate((PPG_seq, newPPG))\n",
    "    ECG_seq = np.concatenate((ECG_seq, newECG))\n",
    "    ABP_seq = np.concatenate((ABP_seq, newABP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "facial-finance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61938, 256, 1) (61938, 256, 1) (61938, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(PPG_seq.shape,ECG_seq.shape,ABP_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "worth-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "np.save(\"PPG_test1.npy\",PPG_seq)\n",
    "np.save(\"ECG_test1.npy\",ECG_seq)\n",
    "np.save(\"ABP_test1.npy\",ABP_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
